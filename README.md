# ğŸ“š Code Documentation RAG System

An intelligent Retrieval-Augmented Generation (RAG) system for software documentation that understands code snippets, API references, and provides contextual code examples with implementation details.

## ğŸ¯ Features

- **Multi-Language Support**: Parse and understand code in Python, JavaScript, TypeScript, Java, C/C++, Go, Rust, Ruby, and PHP
- **Intelligent Code Parsing**: Extract functions, classes, imports, and documentation using AST and tree-sitter
- **Semantic Chunking**: Smart code-aware chunking that preserves context and structure
- **Hybrid Search**: Combines semantic and keyword search for optimal retrieval
- **Context-Aware Generation**: Generate explanations, code examples, API docs, and implementation guides
- **GitHub Integration**: Direct repository cloning and processing
- **Syntax Highlighting**: Beautiful code formatting with Pygments
- **Interactive UI**: Clean Streamlit interface with conversation history

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- OpenAI API key
- GitHub token (optional, for private repos)

### Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/code-doc-rag.git
cd code-doc-rag

2. Install dependencies:

bash
pip install -r requirements.txt

3. Set up environment variables:

bash
cp .env.example .env
# Edit .env and add your API keys

4. Run the application:

bashstreamlit run app.py

ğŸ“– Usage

Enter API Keys: Add your OpenAI API key in the sidebar
Load Repository: Enter a GitHub repository URL and click "Load Repository"
Ask Questions: Type your questions about the code in the main interface
Get Answers: Receive detailed explanations, code examples, or API documentation

Example Queries

"How does the authentication system work?"
"Show me examples of database connections"
"What are the API endpoints for user management?"
"Explain the main class architecture"
"How to implement error handling in this project?"

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  GitHub Loader  â”‚â”€â”€â”€â”€â–¶â”‚ Code Parser  â”‚â”€â”€â”€â”€â–¶â”‚   Chunker    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                      â”‚
                                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Generator    â”‚â—€â”€â”€â”€â”€â”‚  Retriever   â”‚â—€â”€â”€â”€â”€â”‚ Vector Store â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Key Technologies

LangChain: Orchestration framework
ChromaDB: Vector database for embeddings
OpenAI: Embeddings and LLM generation
Tree-sitter: Multi-language code parsing
Streamlit: Web interface
PyGithub: GitHub API integration

ğŸ”§ Configuration
Edit config/settings.py to customize:

Embedding models
LLM models
Chunk sizes
Retrieval parameters
Supported languages and file types

ğŸ“Š Evaluation Metrics
The system includes evaluation capabilities:

Retrieval Accuracy: Precision and recall of retrieved chunks
Response Quality: RAGAS metrics for generation quality
Latency: Query response time measurement
Coverage: Percentage of repository successfully indexed

ğŸš¢ Deployment
Option 1: Streamlit Cloud

Push to GitHub
Connect to Streamlit Cloud
Add secrets in dashboard
Deploy

Option 2: Docker
bashdocker build -t code-doc-rag .
docker run -p 8501:8501 --env-file .env code-doc-rag

Option 3: HuggingFace Spaces

Create new Space
Upload files
Configure secrets
Enable Streamlit SDK

code-doc-rag/
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py       # Configuration settings
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ github_loader.py  # Repository loading
â”‚   â”œâ”€â”€ code_parser.py    # Code parsing logic
â”‚   â”œâ”€â”€ chunking.py       # Document chunking
â”‚   â”œâ”€â”€ embeddings.py     # Embedding generation
â”‚   â”œâ”€â”€ vector_store.py   # Vector DB operations
â”‚   â”œâ”€â”€ retriever.py      # RAG retrieval
â”‚   â””â”€â”€ generator.py      # Response generation
â””â”€â”€ tests/
    â””â”€â”€ test_components.py # Unit tests

ğŸ§ª Testing
Run tests:
bashpytest tests/
ğŸ¤ Contributing

Fork the repository
Create feature branch (git checkout -b feature/amazing-feature)
Commit changes (git commit -m 'Add amazing feature')
Push to branch (git push origin feature/amazing-feature)
Open Pull Request

ğŸ“„ License
MIT License - see LICENSE file for details
ğŸ™ Acknowledgments

OpenAI for GPT and embeddings
LangChain community
Tree-sitter maintainers
Streamlit team

ğŸ“§ Contact
For questions or support, please open an issue on GitHub.

### 12. Environment Variables Template (`.env.example`)

```env
# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here

# GitHub Configuration (Optional)
GITHUB_TOKEN=your-github-token-here

# Model Configuration
EMBEDDING_MODEL=text-embedding-3-small
LLM_MODEL=gpt-4-turbo-preview

# Chunking Configuration
CHUNK_SIZE=1500
CHUNK_OVERLAP=200

# Vector Store Configuration
COLLECTION_NAME=code_documentation
PERSIST_DIRECTORY=./chroma_db

# Retrieval Configuration
TOP_K=5
SIMILARITY_THRESHOLD=0.7